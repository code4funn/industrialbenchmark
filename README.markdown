# Industrial Benchmark 

Requires: Java 8 and Apache Maven 3.x or Python 2.7

Documentation: The documentation is available online at: https://arxiv.org/abs/1709.09480

	Source: D. Hein, S. Depeweg, M. Tokic, S. Udluft, A. Hentschel, T.A. Runkler, and V. Sterzing. "A benchmark 
		environment motivated by industrial control problems," in 2017 IEEE Symposium Series on Computational 
		Intelligence (SSCI), 2017, pp. 1-8. 

## Citing Industrial Benchmark

To cite Industrial Benchmark, please reference:

	D. Hein, S. Depeweg, M. Tokic, S. Udluft, A. Hentschel, T.A. Runkler, and V. Sterzing. "A benchmark environment 
		motivated by industrial control problems," in 2017 IEEE Symposium Series on Computational Intelligence 
		(SSCI), 2017, pp. 1-8. 

Additional references using Industrial Benchmark:
	
	S. Depeweg, J. M. Hernández-Lobato, F. Doshi-Velez, and S. Udluft. "Learning and
		policy search in stochastic dynamical systems with Bayesian neural networks." arXiv
		preprint arXiv:1605.07127, 2016.

	D. Hein, S. Udluft, M. Tokic, A. Hentschel, T.A. Runkler, and V. Sterzing. "Batch reinforcement 
		learning on the industrial benchmark: First experiences," in 2017 International Joint Conference on Neural
		Networks (IJCNN), 2017, pp. 4214–4221.

	S. Depeweg, J. M. Hernández-Lobato, F. Doshi-Velez, and S. Udluft. "Uncertainty decomposition 
		in Bayesian neural networks with latent variables." arXiv preprint arXiv:1605.07127, 2017.
		
	D. Hein, A. Hentschel, T. A. Runkler, and S. Udluft. "Particle Swarm Optimization for Model Predictive 
		Control in Reinforcement Learning Environments," in Y. Shi (Ed.), Critical Developments and Applications 
		of Swarm Intelligence, IGI Global, Hershey, PA, USA, 2018, pp. 401–427.
		
	S. Depeweg, J. M. Hernandez-Lobato, F. Doshi-Velez, and S. Udluft. "Decomposition of Uncertainty in Bayesian 
		Deep Learning for Efficient and Risk-sensitive Learning." 35th International Conference on Machine Learning, 
		ICML 2018. Vol. 3. 2018.
	
	D. Hein, S. Udluft, and T.A. Runkler. "Interpretable policies for reinforcement learning by genetic programming." 
		Engineering Applications of Artificial Intelligence, 76, 2018, pp. 158-169.
	
	D. Hein, S. Udluft, and T.A. Runkler. "Generating interpretable fuzzy controllers using particle swarm 
		optimization and genetic programming," in Proceedings of the Genetic and Evolutionary Computation Conference 
		Companion, ACM, 2018, pp. 1268-1275.
	
	N. Di Palo, and H. Valpola. "Improving Model-Based Control and Active Exploration with Reconstruction 
		Uncertainty Optimization." arXiv preprint arXiv:1812.03955, 2018.
	
	F. Linker. "Industrial Benchmark for Fuzzy Particle Swarm Reinforcement Learning." 
		http://felixlinker.de/doc/ib_fpsrl.pdf, 2019

Additional references mentioning Industrial Benchmark:

	Y. Li. "Deep reinforcement learning: An overview." arXiv preprint arXiv:1701.07274, 2017.
	
	D. Ha, and J. Schmidhuber. "Recurrent world models facilitate policy evolution," in Advances 
		in Neural Information Processing Systems, 2018, pp. 2450-2462.
	
	M. Schaarschmidt, A. Kuhnle, B. Ellis, K. Fricke, F. Gessert, and E. Yoneki. "Lift: Reinforcement learning 
		in computer systems by learning from demonstrations." arXiv preprint arXiv:1808.07903, 2018.
	
	M. Kaiser, C. Otte, T.A. Runkler, and C.H. Ek. "Data Association with Gaussian Processes." arXiv preprint 
		arXiv:1810.07158, 2018.
	
	D. Lee, and J. McNair. "Deep reinforcement learning agent for playing 2D shooting games." Int. J. Control Autom, 
		11, 2018, pp. 193-200.
	
	D. Marino, and M. Manic. "Modeling and planning under uncertainty using deep neural networks." IEEE Transactions 
		on Industrial Informatics, 2019.
